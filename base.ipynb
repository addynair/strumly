{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a8b99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygame\n",
      "  Downloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Downloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0ma \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m02\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pygame\n",
      "Successfully installed pygame-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b925e8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50269afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: Press 1..7 or a..g to select chord A..G. Press 'q' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759239786.599019   27915 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1759239786.601511   32787 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 25.0.7-0ubuntu0.24.04.1), renderer: AMD Radeon Vega 3 Graphics (radeonsi, raven2, ACO, DRM 3.61, 6.14.0-29-generic)\n",
      "W0000 00:00:1759239786.623168   32783 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1759239786.649673   32783 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected chord: A\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pygame\n",
    "try:\n",
    "    import mediapipe as mp\n",
    "except Exception as e:\n",
    "    raise ImportError(\n",
    "        \"Could not import mediapipe. Install with 'pip install mediapipe'.\\n\" + str(e)\n",
    "    )\n",
    "\n",
    "pygame.mixer.init()\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "CHORD_KEYS = {\n",
    "    ord('1'): 'A', ord('2'): 'B', ord('3'): 'C', ord('4'): 'D',\n",
    "    ord('5'): 'E', ord('6'): 'F', ord('7'): 'G',\n",
    "    ord('a'): 'A', ord('b'): 'B', ord('c'): 'C', ord('d'): 'D',\n",
    "    ord('e'): 'E', ord('f'): 'F', ord('g'): 'G',\n",
    "}\n",
    "\n",
    "chords = ['A','B','C','D','E','F','G']\n",
    "selected_chord = 'A'\n",
    "\n",
    "CHORD_IMG_DIR = 'chords'\n",
    "SOUNDS_DIR = 'sounds'\n",
    "\n",
    "STRUM_TOP_RATIO = 0.35\n",
    "STRUM_BOTTOM_RATIO = 0.75\n",
    "NUM_STRINGS = 6\n",
    "\n",
    "HITBOX_TOP_RATIO = 0.38\n",
    "HITBOX_BOTTOM_RATIO = 0.72\n",
    "\n",
    "strum_cooldown = 0.18 \n",
    "\n",
    "STRING_WAV_MAPPING = {\n",
    "    0: 'E3.wav',  \n",
    "    1: 'A3.wav',\n",
    "    2: 'D44.wav',\n",
    "    3: 'G44.wav',\n",
    "    4: 'B44.wav',\n",
    "    5: 'E5.wav',  \n",
    "}\n",
    "\n",
    "def load_chord_image(ch):\n",
    "    path = os.path.join(CHORD_IMG_DIR, f\"{ch}.png\")\n",
    "    if os.path.exists(path):\n",
    "        img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is None:\n",
    "            return None\n",
    "        if img.shape[2] == 4:\n",
    "            alpha = img[:,:,3] / 255.0\n",
    "            img_rgb = img[:,:,:3].astype(np.float32)\n",
    "            for c in range(3):\n",
    "                img[:,:,c] = (alpha * img_rgb[:,:,c] + (1-alpha)*255).astype(np.uint8)\n",
    "            img = img[:,:,:3]\n",
    "        return img\n",
    "    return None\n",
    "\n",
    "chord_images = {c: load_chord_image(c) for c in chords}\n",
    "\n",
    "\n",
    "last_play_times = [0]*NUM_STRINGS  \n",
    "\n",
    "def play_string(string_index):\n",
    "    now = time.time()\n",
    "    if now - last_play_times[string_index] < strum_cooldown:\n",
    "        return\n",
    "    last_play_times[string_index] = now\n",
    "    path = os.path.join(SOUNDS_DIR, STRING_WAV_MAPPING.get(string_index, 'E3.wav'))\n",
    "    if not os.path.exists(path):\n",
    "        print(\"Sound not found:\", path)\n",
    "        return\n",
    "    try:\n",
    "        sound = pygame.mixer.Sound(path)\n",
    "        sound.play()\n",
    "    except Exception as e:\n",
    "        print(\"Error playing sound:\", e)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Could not open webcam.\")\n",
    "\n",
    "\n",
    "is_in_top = False\n",
    "top_cross_time = None\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.6,\n",
    "    min_tracking_confidence=0.6\n",
    ") as hands:\n",
    "    print(\"Controls: Press 1..7 or a..g to select chord A..G. Press 'q' to quit.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to read frame.\")\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        h, w, _ = frame.shape\n",
    "\n",
    "    \n",
    "        strum_top = int(h * STRUM_TOP_RATIO)\n",
    "        strum_bottom = int(h * STRUM_BOTTOM_RATIO)\n",
    "        cv2.rectangle(frame, (0, strum_top-10), (w, strum_bottom+10), (230,230,230), -1)\n",
    "\n",
    "        string_positions = []\n",
    "        for i in range(NUM_STRINGS):\n",
    "            y = int(strum_top + (i / (NUM_STRINGS-1)) * (strum_bottom - strum_top))\n",
    "            string_positions.append(y)\n",
    "            cv2.line(frame, (0, y), (w, y), (60,60,60), 2)\n",
    "\n",
    "        hit_top = int(h * HITBOX_TOP_RATIO)\n",
    "        hit_bottom = int(h * HITBOX_BOTTOM_RATIO)\n",
    "        cv2.line(frame, (0, hit_top), (w, hit_top), (0,120,255), 2)\n",
    "        cv2.line(frame, (0, hit_bottom), (w, hit_bottom), (0,120,255), 2)\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(rgb)\n",
    "\n",
    "        if results.multi_hand_landmarks and results.multi_handedness:\n",
    "            for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "                label = handedness.classification[0].label\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                lm12 = hand_landmarks.landmark[12]\n",
    "                x_px = int(lm12.x * w)\n",
    "                y_px = int(lm12.y * h)\n",
    "                cv2.circle(frame, (x_px, y_px), 6, (0,255,0), -1)\n",
    "                cv2.putText(frame, f\"{label}\", (x_px+8, y_px-8), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
    "\n",
    "                if label.lower() == \"right\":\n",
    "                    for i, y_str in enumerate(string_positions):\n",
    "                        if abs(y_px - y_str) < 12:  \n",
    "                            play_string(i)\n",
    "                            break\n",
    "\n",
    "        instr_w = int(w * 0.20)\n",
    "        instr_h = int(h * 0.25)\n",
    "        instr_img = chord_images.get(selected_chord)\n",
    "        if instr_img is not None:\n",
    "            ih, iw = instr_img.shape[:2]\n",
    "            scale = min(instr_w / iw, instr_h / ih)\n",
    "            new_w = int(iw * scale)\n",
    "            new_h = int(ih * scale)\n",
    "            resized = cv2.resize(instr_img, (new_w, new_h))\n",
    "            frame[5:5+new_h, 5:5+new_w] = resized\n",
    "        else:\n",
    "            cv2.rectangle(frame, (5,5), (5+instr_w, 5+instr_h), (50,50,50), -1)\n",
    "            cv2.putText(frame, f\"{selected_chord}\", (12, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2)\n",
    "\n",
    "        cv2.putText(frame, f\"Selected chord: {selected_chord}   (press 1..7 or a..g)\", (10, h-20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "\n",
    "        cv2.imshow(\"Virtual Guitar Prototype (press q to quit)\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key in CHORD_KEYS:\n",
    "            selected_chord = CHORD_KEYS[key]\n",
    "            print(\"Selected chord:\", selected_chord)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aee688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guitar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
